---
layout: post #默认post布局

title: Ollama使用记录
description: Ollama踩坑全记录
author: [diexie, ] # 此处可以简写，详细添加在 _data/authors.yml 中
date: 2025-02-25 11:33:00 +0800

pin: false # 置顶
categories: [深度学习] # 分类,第一个为主分类
tags: [LLM, 软件] # 标签

math: true # 支持数学公式
toc: true # 支持侧边目录
comments: true # 支持评论
mermaid: true # 支持mermaid图表

# cdn: https://xxxx.com/ # CDN加速，可以与media_subpath配合使用：[site.cdn/][page.media_subpath/]file.ext
# media_subpath: /assets/img/ # 媒体文件路径，用于简写本地图片等媒体文件路径，注意：封面图路径**会受影响**

image:
  path: https://picx.zhimg.com/70/v2-eaec95835ad51dbdb0ed240cae7dc4f1_1440w.avis?source=172ae18b&biz_tag=Post # 封面图
  lqip: data:image/webp # lqip占位符，用于图片懒加载
  alt: 『这是头图的描述』 # 头图描述
---

> 仅作Linux下使用记录，Windows下使用请参考官方文档

## 参考链接

[官网](https://ollama.com/)
[官方文档](https://github.com/ollama/ollama/tree/main/docs)
[Linux 使用文档](https://github.com/ollama/ollama/blob/main/docs/linux.md)

## 安装

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

## 基础使用

```bash
ollama --help # 查看帮助

Usage:
  ollama [flags]
  ollama [command]

Available Commands:
  serve       Start ollama
  create      Create a model from a Modelfile
  show        Show information for a model
  run         Run a model
  stop        Stop a running model
  pull        Pull a model from a registry
  push        Push a model to a registry
  list        List models
  ps          List running models
  cp          Copy a model
  rm          Remove a model
  help        Help about any command

Flags:
  -h, --help      help for ollama
  -v, --version   Show version information
```

## 使用systemd启动Ollama serve

建议使用systemd启动Ollama，以下是启动Ollama的方法：

```bash
sudo systemctl start ollama # 启动服务
sudo systemctl status ollama # 查看服务状态
```

## 切换监听端口

Ollama默认监听`127.0.0.1:11434`，为了方便外部访问，我们希望其监听`0.0.0.0:11434`，以下是切换监听端口的方法：

### 在bash上直接运行的Ollama(不推荐)

```bash
export OLLAMA_HOST=0.0.0.0:11434
ollama serve
```

### 使用systemd服务的Ollama(推荐)

```bash
sudo vim /etc/systemd/system/ollama.service # 编辑服务配置文件

# 在[Service]下添加
Environment="OLLAMA_HOST=0.0.0.0"

sudo systemctl daemon-reload # 重新加载配置
sudo systemctl restart ollama # 重启服务
```

同时介绍systemd服务的其他常用命令：

```bash
sudo systemctl start ollama # 启动服务
sudo systemctl stop ollama # 停止服务
sudo systemctl restart ollama # 重启服务
sudo systemctl status ollama # 查看服务状态

journalctl -u ollama # 查看服务日志
```

## 卸载

请严格按照以下步骤卸载Ollama：

```bash
sudo systemctl stop ollama # 停止服务
sudo systemctl disable ollama # 禁用服务
sudo rm /etc/systemd/system/ollama.service # 删除服务配置文件

sudo rm $(which ollama) # 删除可执行文件

sudo rm -r /usr/share/ollama # 删除资源文件(如下载的模型，可选)
sudo userdel ollama # 删除用户
sudo groupdel ollama # 删除用户组

sudo rm -rf /usr/local/lib/ollama # 删除依赖库
```

或参考[官方文档](https://github.com/ollama/ollama/blob/main/docs/linux.md#uninstall)

## Windows下使用及问题汇总

> 由于某些服务器使用了windows，因此补充部分windows下Ollama的说明

参考链接:

[博客](https://www.cnblogs.com/mq0036/p/18715829)

### 安装

请前往[官网](https://ollama.com/)下载安装包，安装完成后，将`ollama.exe`添加到环境变量中。

### 添加环境变量

相较于Linux，Windows下添加环境变量较为简单

直接前往`系统属性`->`高级`->`环境变量`->`系统变量` 中添加相应环境变量即可。

相关环境变量说明:

| 环境变量            | 说明                                |
| ------------------- | ----------------------------------- |
| OLLAMA_HOST         | 监听地址，默认为127.0.0.1           |
| OLLAMA_MODELS       | 模型存储路径，建议修改              |
| OLLAMA_PORT         | 监听端口，默认为11434               |
| OLLAMA_KEEP_ALIVE   | 保持连接时间，默认为5m, 建议设为24h |
| OLLAMA_NUM_PARALLEL | 表示请求处理的并发数，默认为1       |
| OLLAMA_MAX_QUEUE    | 表示请求队列的最大长度，默认为512   |

### 使用

与Linux下使用相同，命令行输入`ollama --help`查看帮助。

```bash
ollama serve # 启动服务
```

### 服务的停止与重启

要停止Ollama，直接在`任务管理器`->`启动`中禁用`ollama.exe`并在`进程`中结束`ollama.exe`来停止服务。

之后使用 `ollama serve` 重新启动服务。

